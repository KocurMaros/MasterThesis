%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Saved with string encoding Unicode (UTF-8) 


@article{CANAL2022593,
title = {A survey on facial emotion recognition techniques: A state-of-the-art literature review},
journal = {Information Sciences},
volume = {582},
pages = {593-617},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521010136},
author = {Felipe Zago Canal and Tobias Rossi Müller and Jhennifer Cristine Matias and Gustavo Gino Scotton and Antonio Reis {de Sa Junior} and Eliane Pozzebon and Antonio Carlos Sobieranski},
keywords = {Emotion Recognition, Facial emotion recognition, Pattern recognition, Systematic literature review},
abstract = {In this survey, a systematic literature review of the state-of-the-art on emotion expression recognition from facial images is presented. The paper has as main objective arise the most commonly used strategies employed to interpret and recognize facial emotion expressions, published over the past few years. For this purpose, a total of 51 papers were analyzed over the literature totaling 94 distinct methods, collected from well-established scientific databases (ACM Digital Library, IEEE Xplore, Science Direct and Scopus), whose works were categorized according to its main construction concept. From the analyzed works, it was possible to categorize them into two main trends: classical and those approaches specifically designed by the use of neural networks. The obtained statistical analysis demonstrated a marginally better recognition precision for the classical approaches when faced to neural networks counterpart, but with a reduced capacity of generalization. Additionally, the present study verified the most popular datasets for facial expression and emotion recognition showing the pros and cons each and, thereby, demonstrating a real demand for reliable data-sources regarding artificial and natural experimental environments.}
}


@Article{s18020401,
AUTHOR = {Ko, Byoung Chul},
TITLE = {A Brief Review of Facial Emotion Recognition Based on Visual Information},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {401},
URL = {https://www.mdpi.com/1424-8220/18/2/401},
PubMedID = {29385749},
ISSN = {1424-8220},
ABSTRACT = {Facial emotion recognition (FER) is an important topic in the fields of computer vision and artificial intelligence owing to its significant academic and commercial potential. Although FER can be conducted using multiple sensors, this review focuses on studies that exclusively use facial images, because visual expressions are one of the main information channels in interpersonal communication. This paper provides a brief review of researches in the field of FER conducted over the past decades. First, conventional FER approaches are described along with a summary of the representative categories of FER systems and their main algorithms. Deep-learning-based FER approaches using deep networks enabling “end-to-end” learning are then presented. This review also focuses on an up-to-date hybrid deep-learning approach combining a convolutional neural network (CNN) for the spatial features of an individual frame and long short-term memory (LSTM) for temporal features of consecutive frames. In the later part of this paper, a brief review of publicly available evaluation metrics is given, and a comparison with benchmark results, which are a standard for a quantitative comparison of FER researches, is described. This review can serve as a brief guidebook to newcomers in the field of FER, providing basic knowledge and a general understanding of the latest state-of-the-art studies, as well as to experienced researchers looking for productive directions for future work.},
DOI = {10.3390/s18020401}
}
@ARTICLE{9674818,
  author={Bisogni, Carmen and Castiglione, Aniello and Hossain, Sanoar and Narducci, Fabio and Umer, Saiyed},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Impact of Deep Learning Approaches on Facial Expression Recognition in Healthcare Industries}, 
  year={2022},
  volume={18},
  number={8},
  pages={5619-5627},
  keywords={Face recognition;Feature extraction;Medical services;Convolutional neural networks;Informatics;Industries;Databases;Convolutional neural networks (CNNs);deep learning;facial expression;recognition;score-level fusion},
  doi={10.1109/TII.2022.3141400}
}
@INPROCEEDINGS{8614755,
  author={Wang, Huan-Huan and Gu, Jing-Wei},
  booktitle={2018 IEEE International Conference on Advanced Manufacturing (ICAM)}, 
  title={The Applications of Facial Expression Recognition in Human-computer Interaction}, 
  year={2018},
  volume={},
  number={},
  pages={288-291},
  keywords={Feature extraction;Face recognition;Hidden Markov models;Human computer interaction;Deep learning;Emotion recognition;Manufacturing;expression recognition;human-computer interaction;convolutional neural network},
  doi={10.1109/AMCON.2018.8614755}
}
@Inbook{Martinez2016,
author="Martinez, Brais
and Valstar, Michel F.",
editor="Kawulok, Michal
and Celebi, M. Emre
and Smolka, Bogdan",
title="Advances, Challenges, and Opportunities in Automatic Facial Expression Recognition",
bookTitle="Advances in Face Detection and Facial Image Analysis",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="63--100",
abstract="In this chapter we consider the problem of automatic facial expression analysis. Our take on this is that the field has reached a point where it needs to move away from considering experiments and applications under in-the-lab conditions, and move towards so-called in-the-wild scenarios. We assume throughout this chapter that the aim is to develop technology that can be deployed in practical applications under unconstrained conditions. While some first efforts in this direction have been reported very recently, it is still unclear what the right path to achieving accurate, informative, robust, and real-time facial expression analysis will be. To illuminate the journey ahead, we first provide in Sect.{\thinspace}1 an overview of the existing theories and specific problem formulations considered within the computer vision community. Then we describe in Sect.{\thinspace}2 the standard algorithmic pipeline which is common to most facial expression analysis algorithms. We include suggestions as to which of the current algorithms and approaches are most suited to the scenario considered. In Sect.{\thinspace}3 we describe our view of the remaining challenges, and the current opportunities within the field. This chapter is thus not intended as a review of different approaches, but rather a selection of what we believe are the most suitable state-of-the-art algorithms, and a selection of exemplars chosen to characterise a specific approach. We review in Sect.{\thinspace}4 some of the exciting opportunities for the application of automatic facial expression analysis to everyday practical problems and current commercial applications being exploited. Section 5 ends the chapter by summarising the major conclusions drawn.",
isbn="978-3-319-25958-1",
doi="10.1007/978-3-319-25958-1_4",
url="https://doi.org/10.1007/978-3-319-25958-1_4"
}
@article{HE2021107930,
title = {Identification of facial expression using a multiple impression feedback recognition model},
journal = {Applied Soft Computing},
volume = {113},
pages = {107930},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107930},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621008528},
author = {Hong He and Shuda Chen},
keywords = {Facial expression recognition, Deep feedback learning, Support vector machine, Discrete wavelet transform},
abstract = {Facial expression recognition (FER) plays a vital role in the automatic detection of human emotions with intelligent machine. Since the FER is an interdisciplinary technique involving biology, computer science and even psychology, more challenges will be encountered as we pursue a high recognition accuracy of facial expressions. Inspired by the progressive enhancing procedure of face recognition of human, we proposed a multiple impression feedback recognition model (MIFR) for the identification of facial expression. Different from current deep learning techniques, the MIFR realizes a quick facial expression recognition through cascade feedback recognition cycles. Multiple impression features of an FER image are firstly obtained by the discrete wavelet decomposition (DWT). Each recognition cycle is implemented by inputting wavelet impression features in a specific decomposition scale into a classifier set of parallel Support Vector Machines (SVMs). In terms of coarse-to-fine wavelet features on multiple scales, the recognition results are gradually improved through integrating classification probability vectors of multiple cycles. In order to validate the performance of the MIFR_SVM for face expression recognition, we also conducted an experiment of facial multi-view expression with occlusion (FMEO) in the laboratory. Three traditional schemes and seven deep learning schemes have been chosen for the FER comparison of three public datasets and one lab dataset FMEO. The classification results show that the MIFR_SVM is not only superior than traditional schemes, but also performs better than deep learning techniques, including both neural-network-based ones and random-forest-based ones. The average recognition accuracy of MIFR_SVM reaches to 92.31% for four datasets. Furthermore, the MIFR_SVM has fewer parameters, less complexity and adaptable cascade structure, which is more suitable for the image datasets with small size or with diverse qualities.}
}
@article{SAXENA202239,
title = {An intelligent facial expression recognition system with emotion intensity classification},
journal = {Cognitive Systems Research},
volume = {74},
pages = {39-52},
year = {2022},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722000171},
author = {Suchitra Saxena and Shikha Tripathi and T.S.B. Sudarshan},
keywords = {Facial expression recognition, Deep Learning, Facial expression intensity level, Expression intensity classification, Robotic Process Automation, Human Machine Interaction},
abstract = {Facial expressions play a crucial role in emotion recognition as compared to other modalities. In this work, an integrated network, which is capable of recognizing emotion intensity levels from facial images in real time using deep learning technique is proposed. The cognitive study of facial expressions based on expression intensity levels are useful in applications such as healthcare, coboting, Industry 4.0 etc. This work proposes to augment emotion recognition with 2 other important parameters, valence and emotion intensity. This helps in better automated responses by a machine to an emotion. The valence model helps in classifying emotion as positive and negative emotions and discrete model classifies emotions as happy, anger, disgust, surprise and neutral state using Convolution Neural Network (CNN). Feature extraction and classification are carried out using CMU Multi-PIE database. The proposed architecture achieves 99.1% and 99.11% accuracy for valence model and discrete model respectively for offline image data with 5-fold cross validation. The average accuracy achieved in real time for valance model and discrete model is 95% & 95.6% respectively. Also, this work contributes to build a new database using facial landmarks, with three intensity levels of facial expressions which helps to classify expressions into low, mild and high intensities. The performance is also tested for different classifiers. The proposed integrated system is configured for real time Human Robot Interaction (HRI) applications on a test bed consisting of Raspberry Pi and RPA platform to assess its performance.}
}
@misc{roy2024resemotenetbridgingaccuracyloss,
      title={ResEmoteNet: Bridging Accuracy and Loss Reduction in Facial Emotion Recognition}, 
      author={Arnab Kumar Roy and Hemant Kumar Kathania and Adhitiya Sharma and Abhishek Dey and Md. Sarfaraj Alam Ansari},
      year={2024},
      eprint={2409.10545},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.10545}, 
}

@Article{electronics12173595,
AUTHOR = {Zhang, Saining and Zhang, Yuhang and Zhang, Ye and Wang, Yufei and Song, Zhigang},
TITLE = {A Dual-Direction Attention Mixed Feature Network for Facial Expression Recognition},
JOURNAL = {Electronics},
VOLUME = {12},
YEAR = {2023},
NUMBER = {17},
ARTICLE-NUMBER = {3595},
URL = {https://www.mdpi.com/2079-9292/12/17/3595},
ISSN = {2079-9292},
ABSTRACT = {In recent years, facial expression recognition (FER) has garnered significant attention within the realm of computer vision research. This paper presents an innovative network called the Dual-Direction Attention Mixed Feature Network (DDAMFN) specifically designed for FER, boasting both robustness and lightweight characteristics. The network architecture comprises two primary components: the Mixed Feature Network (MFN) serving as the backbone, and the Dual-Direction Attention Network (DDAN) functioning as the head. To enhance the network’s capability in the MFN, resilient features are extracted by utilizing mixed-size kernels. Additionally, a new Dual-Direction Attention (DDA) head that generates attention maps in two orientations is proposed, enabling the model to capture long-range dependencies effectively. To further improve the accuracy, a novel attention loss mechanism for the DDAN is introduced with different heads focusing on distinct areas of the input. Experimental evaluations on several widely used public datasets, including AffectNet, RAF-DB, and FERPlus, demonstrate the superiority of the DDAMFN compared to other existing models, which establishes that the DDAMFN as the state-of-the-art model in the field of FER.},
DOI = {10.3390/electronics12173595}
}
@Article{Huang2023,
author={Huang, Zi-Yu
and Chiang, Chia-Chin
and Chen, Jian-Hao
and Chen, Yi-Chian
and Chung, Hsin-Lung
and Cai, Yu-Ping
and Hsu, Hsiu-Chuan},
title={A study on computer vision for facial emotion recognition},
journal={Scientific Reports},
year={2023},
month={May},
day={24},
volume={13},
number={1},
pages={8425},
abstract={Artificial intelligence has been successfully applied in various fields, one of which is computer vision. In this study, a deep neural network (DNN) was adopted for Facial emotion recognition (FER). One of the objectives in this study is to identify the critical facial features on which the DNN model focuses for FER. In particular, we utilized a convolutional neural network (CNN), the combination of squeeze-and-excitation network and the residual neural network, for the task of FER. We utilized AffectNet and the Real-World Affective Faces Database (RAF-DB) as the facial expression databases that provide learning samples for the CNN. The feature maps were extracted from the residual blocks for further analysis. Our analysis shows that the features around the nose and mouth are critical facial landmarks for the neural networks. Cross-database validations were conducted between the databases. The network model trained on AffectNet achieved 77.37{\%} accuracy when validated on the RAF-DB, while the network model pretrained on AffectNet and then transfer learned on the RAF-DB results in validation accuracy of 83.37{\%}. The outcomes of this study would improve the understanding of neural networks and assist with improving computer vision accuracy.},
issn={2045-2322},
doi={10.1038/s41598-023-35446-4},
url={https://doi.org/10.1038/s41598-023-35446-4}
}
